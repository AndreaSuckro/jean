\documentclass[main.tex]{subfiles}
\begin{document}
\chapter{Introduction}
Hypothesis testing has always been the fundamental tool of scientific research. Conducting test cases that vary the variable under introspection, recording the results and using statistic methods to determine significant results is the current methodology that shall ensure objective insights. This approach is more and more adapted for business research as well. In the context of marketing it is called A/B Testing and is used to gather insights about the customers behavior under varying conditions. The process is similar to the steps in a scientific set up. The participants are selected randomly from the customer base and are presented with a base condition (the unchanged product) or one or more variants of it. The customers feedback is then collected and used to analyze whether the new feature is a significant success or failure.

As computations on big sets of data are getting more tangible, automated A/B Testing becomes part of many online services or products. In fact by using online products like Google or Facebook it is highly likely that most of us have already been taking part in such an experiment and though that raises some attention sometimes~\cite{arthur2014facebook} most of these tests go by unnoticed. The term itself originates from a simplified setting where only two variants are compared but is also used to describe settings with more scenarios that are referred to as Multivariate testing in the scientific setting. 

Over the years more and more products came to the market, helping companies to conduct their own A/B Testing, all the while still using the same traditional statistical model for the analysis of the collected data. In the meantime scientific research in the field of Machine Learning and Cognitive Science strived forward, trying to discover concepts like learning and decision making. New algorithms were developed and compared with actual human behavior (see for example the article ``Cheap but Clever: Human Active Learning in a Bandit Setting'' by Shunan Zang and Angela J Yu~\cite{zhang2013cheap}). Slowly those theoretical models found their way to the industry and started a discussion about whether this is the new, right way to do testing.

Experimenters hope for realistic feedback by directly measuring the users behavior without additional work by the customer (as compared to filling out a survey for example). The gained insight should be used to more reliably model users future behavior and to extract behavior patterns possibly unknown prior to the experiment. This procedure is not bound to user studies as experiments can be conducted on back-end algorithms as well.

\section{Terminology}
Certain terms are common in the framework of A/B Testing and will therefore also appear repeatedly throughout this thesis. The following explanation will set them into context.
\begin{description}
\item[Test]
A test is created with a fixed number of buckets ranging from 2 to $n$. It is also defined what proportion of the users of the tested product shall take part in the test. This number is called the sampling rate and determines whether a user is taken in consideration before she is assigned to a bucket. The test is active for a preset amount of time, collecting the data to determine if there is a significant difference between the buckets.
\item[Bucket]
A bucket is a scenario that resides within a test. Buckets vary on a certain feature that is the discriminating factor to be measured by the overall test. This can be a new design or UI-feature, but basically it is not tied to a `visible' change, but can also be concerned with internal mechanisms. The percentage of users that get assigned to a specific bucket can be freely administrated as long as the percentages sum up to $100\%$ .
\item[Assignment]
An assignment determines the experience the user will be exposed to during the test. Once determined it stays fixed, meaning that a user will never be exposed to different buckets throughout one test.
\item[Action]
A user with an assignment may perform an action that is measured. For example -- the clicking on a specific button triggers a recording of this action. The accumulated actions determine the success of a bucket compared to the others. 
\end{description}
\section{Workflow of a Testing System}
Encapsulating the process of administrating and measuring A/B Tests is the purpose of any A/B Testing system. Experimenters have the possibility to create and monitor their tests from such systems, allowing them to keep track of the tests that are running for their product and keep also a history for already finished tests. The following steps describe the different parts that are inherent to those testing platforms.
\subsection{Creating a Test} 
A test is created with the above described properties. Once that is done, the experimenter has to tie the assignments a user gets to different experiences in the tested product. The A/B Testing service is ignorant towards the concrete differences that are tested -- it only handles the administration of the assignments. The experimenter also needs to define when an action is created and send this to the A/B Testing service so that it can collect the action data and provide analysis on it.
\subsection{Running the Test}
For every new user who is visiting the tested product the A/B Testing service determines if she is part of the experiment based on the sampling rate. If she takes part in the testing the next step for the A/B Testing service is to decide the bucket she is assigned to. The user will from now on always stay in the bucket to avoid shifting experiences from visit to visit.
\subsection{Analyzing the Result}
The service provides metrics and current states of the buckets throughout the testing phase. Though it is not encouraged, experimenters can still update their tests and for example increase the sampling rate or disable whole buckets, if they are not useful anymore.

\section{Example Scenario}
Intuit is a software company that focuses on products in the  financial and tax preparation sector as well as related services for small businesses, accountants and individuals. The data engineering and analytics group within Intuit has developed a framework to conduct A/B Tests called \emph{jabba}. It is a web service that can be integrated by any online product and uses HTTP (Hypertext Transfer Protocol) requests to measure the characteristic numbers for a test. I will use this service as an exemplary implementation for an A/B Testing service throughout the thesis. A simple use case is now described in the following section.\newline
Imagine a product team that wants to rise awareness of password security for their existing users. They discuss two ways to do that:
\begin{enumerate}
  \item Sending out an email that informs the user of the importance of a strong password
  \item Placing a banner on their products landing page that contains the same information
\end{enumerate}
They create a test in jabba and specify that the test should be active for three weeks with a sampling rate of $5\%$. They generate two buckets: Bucket A for the email and Bucket B for the landing page. Each bucket get's $50\%$ of the $5\%$ of overall users that participate in the test. Once the test is started, the product makes a call to jabba for each user that logs in to the system. Jabba determines whether the user participates in the test and if so in which bucket. The product shows depending on the returned assignment whether the user experiences no changes (she falls outside the $5\%$ sampling percentage), the email (Bucket A) or the security banner (Bucket B). If the user changes her password during the time the test is active it counts as an action that is send to jabba as well. After the testing period is over jabba reports the performance of each bucket and whether one was significantly better than the other and the product group can decide which feature they want to roll out for all their users.

\end{document}