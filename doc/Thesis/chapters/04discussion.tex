\documentclass[main.tex]{subfiles}
\begin{document}
\chapter{Discussion}
Although Bandit and regular A/B Testing algorithms have a lot in common they do not really solve for the same problem which makes a clear decision upon what is better very hard. The Bandit Algorithms make more sense in an ongoing test setting, where the environment can change through the trial and a Test is never really finished. This also entails that users have to cope with possibly more changes from time to time. In fact when coming back to the limitations that were set at the beginning of the thesis more points come up that may cause troubles.

\section{The Limitations of the Used Restrictions}
In the beginning of the thesis we applied some simplifications to the problem of A/B Testing. The number of Buckets was restricted to two which is not to harmful since no algorithm takes this as a hard precondition, although it can affect optimization. This means that the described methods work for more Buckets as well. Specifically for the Bandit Algorithms it makes sense to use UCB or Thompson Sampling for a Test with more Buckets, since in the previously described setting they did not perform much better than the simpler Bandit Algorithms.

Another big factor is that for a normal A/B Test one does not know when the customer is producing the event. He may come to the tested page but not click the specified link or button. This means that until the user really performs an action we can only speak of a non-click event with a certain probability. For modeling this probability data from previous tests could be utilized, making it more and more likely that the user will not click as more time passes by. Users can also provide more than one Event, making the samples not independent anymore. It is not really clear how the Bandit algorithms have to be adapted in a way that they support this setting.

The described methods make not use of a prior so far. Using previous test runs could provide a distribution over the differences between Buckets. This distribution is most likely shaped similar to an exponential decay function, making small differences between Buckets more likely than huge differences. This prior can easily be integrated in the Analytic and Bandit's approach.

\section{Duration of the Test}
Just comparing the duration of the test, one could argue that Bandit algorithms are useful if they keep on running in the background of a product/service and not turned of at a certain time, hence rendering the question for statistical significance useless. And since they are adapting dynamically one could react to changes occurring later in time. This is a theoretical solid idea, but it leads also to several implications that are possibly not easy to be resolved: Imagine a reasonable sized application or service. If testing proofs valuable this application will not just have one test running at a time. They have to be maintained in the code and customer service has to handle several possible states the application is in. This 

No statistical model can compensate for a test that is not run long enough to cover different behavioral patterns of the targeted users during time. Meaning that for any useful test the cycles that are important have to be identified first (work-weekend, day-night, differences in timezone) and the duration adapted to account for those.

% the end :)
\end{document}